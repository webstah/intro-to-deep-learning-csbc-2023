{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_data = datasets.CIFAR10(root='./data', train=True,\n",
    "                              download=True, transform=transform)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size,\n",
    "                              shuffle=True, num_workers=2)\n",
    "\n",
    "test_data = datasets.CIFAR10(root='./data', train=False,\n",
    "                             download=True, transform=transform)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size,\n",
    "                             shuffle=False, num_workers=2)\n",
    "\n",
    "# plane, car, bird, cat, deer, dog, frog, horse, ship, truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "# get batch from dataloader\n",
    "sampler = enumerate(train_dataloader)\n",
    "batch_idx, (x, y) = next(sampler)\n",
    "print(batch_idx, x.shape, y.shape)\n",
    "\n",
    "# select sample images\n",
    "images = [x[i].squeeze().permute(1, 2, 0).numpy()/2 + 0.5 for i in range(16)]\n",
    "\n",
    "# create and display plot\n",
    "fig = plt.figure()\n",
    "grid = ImageGrid(fig, 111,\n",
    "                 nrows_ncols=(4, 4),\n",
    "                 axes_pad=0.1,\n",
    ")\n",
    "for axis, image in zip(grid, images):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    axis.imshow(image)\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# create model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training and test steps\n",
    "def train(model, ce_loss, optimizer, dataloader):\n",
    "  model.train()\n",
    "  losses = []\n",
    "  accuracies = []\n",
    "  for batch_idx, (x, y) in enumerate(dataloader):\n",
    "    x, y = x.to('cuda'), y.to('cuda')\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = model(x)\n",
    "    loss = ce_loss(pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    accuracy = torch.mean((torch.argmax(pred, dim=-1) == y).float())\n",
    "\n",
    "    losses.append(loss.detach().cpu())\n",
    "    accuracies.append(accuracy.cpu())\n",
    "\n",
    "  return torch.mean(torch.stack(losses, dim=0)), torch.mean(torch.stack(accuracies, dim=0))\n",
    "\n",
    "def test(model, ce_loss, dataloader):\n",
    "  model.eval()\n",
    "  losses = []\n",
    "  accuracies = []\n",
    "  for batch_idx, (x, y) in enumerate(dataloader):\n",
    "    x, y = x.to('cuda'), y.to('cuda')\n",
    "\n",
    "    pred = model(x)\n",
    "    loss = ce_loss(pred, y)\n",
    "\n",
    "    accuracy = torch.mean((torch.argmax(pred, dim=-1) == y).float())\n",
    "\n",
    "    losses.append(loss.detach().cpu())\n",
    "    accuracies.append(accuracy.cpu())\n",
    "    \n",
    "  return torch.mean(torch.stack(losses, dim=0)), torch.mean(torch.stack(accuracies, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = 30\n",
    "lr = 1e-2\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# create model, optimizer, and loss function\n",
    "model = CNN().to('cuda')\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, \n",
    "                      weight_decay=weight_decay, momentum=momentum)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "for epoch in range(num_epochs):\n",
    "  train_loss, train_accuracy = train(model, ce_loss, optimizer, train_dataloader)\n",
    "  test_loss, test_accuracy = test(model, ce_loss, test_dataloader)\n",
    "\n",
    "  print(f'[{epoch}] Train loss: {train_loss.item():.2f}, Train Accuracy: {train_accuracy.item():.2f}, Test loss: {test_loss.item():.2f}, Test Accuracy: {test_accuracy.item():.2f}')\n",
    "\n",
    "  train_losses.append(train_loss.item())\n",
    "  test_losses.append(test_loss.item())\n",
    "  train_accuracies.append(train_accuracy.item())\n",
    "  test_accuracies.append(test_accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# create model\n",
    "class CNNBatchNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "num_epochs = 30\n",
    "lr = 1e-2\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# create model, optimizer, and loss function\n",
    "model = CNNBatchNorm().to('cuda')\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, \n",
    "                      weight_decay=weight_decay, momentum=momentum)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "for epoch in range(num_epochs):\n",
    "  train_loss, train_accuracy = train(model, ce_loss, optimizer, train_dataloader)\n",
    "  test_loss, test_accuracy = test(model, ce_loss, test_dataloader)\n",
    "\n",
    "  print(f'[{epoch}] Train loss: {train_loss.item():.2f}, Train Accuracy: {train_accuracy.item():.2f}, Test loss: {test_loss.item():.2f}, Test Accuracy: {test_accuracy.item():.2f}')\n",
    "\n",
    "  train_losses.append(train_loss.item())\n",
    "  test_losses.append(test_loss.item())\n",
    "  train_accuracies.append(train_accuracy.item())\n",
    "  test_accuracies.append(test_accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# create model\n",
    "class CNNDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "num_epochs = 30\n",
    "lr = 1e-2\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# create model, optimizer, and loss function\n",
    "model = CNNDropout().to('cuda')\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, \n",
    "                      weight_decay=weight_decay, momentum=momentum)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "for epoch in range(num_epochs):\n",
    "  train_loss, train_accuracy = train(model, ce_loss, optimizer, train_dataloader)\n",
    "  test_loss, test_accuracy = test(model, ce_loss, test_dataloader)\n",
    "\n",
    "  print(f'[{epoch}] Train loss: {train_loss.item():.2f}, Train Accuracy: {train_accuracy.item():.2f}, Test loss: {test_loss.item():.2f}, Test Accuracy: {test_accuracy.item():.2f}')\n",
    "\n",
    "  train_losses.append(train_loss.item())\n",
    "  test_losses.append(test_loss.item())\n",
    "  train_accuracies.append(train_accuracy.item())\n",
    "  test_accuracies.append(test_accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do data augmentation for homework..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
